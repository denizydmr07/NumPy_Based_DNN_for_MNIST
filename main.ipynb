{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries I will use to build the model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to install mnist dataset from web\n",
    "import gzip\n",
    "import os\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(\"Downloading \", filename)\n",
    "        urlretrieve(url, filename)\n",
    "    else:\n",
    "        print(\"File \", filename, \" already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_images(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    return data.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  train-images-idx3-ubyte.gz  already exists.\n",
      "File  train-labels-idx1-ubyte.gz  already exists.\n",
      "File  t10k-images-idx3-ubyte.gz  already exists.\n",
      "File  t10k-labels-idx1-ubyte.gz  already exists.\n"
     ]
    }
   ],
   "source": [
    "# Downloading the MNIST dataset\n",
    "base_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "download_mnist(base_url + 'train-images-idx3-ubyte.gz', \"train-images-idx3-ubyte.gz\")\n",
    "download_mnist(base_url + 'train-labels-idx1-ubyte.gz', \"train-labels-idx1-ubyte.gz\")\n",
    "download_mnist(base_url + 't10k-images-idx3-ubyte.gz', \"t10k-images-idx3-ubyte.gz\")\n",
    "download_mnist(base_url + 't10k-labels-idx1-ubyte.gz', \"t10k-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading and converting the data to numpy arrays\n",
    "X_train = read_mnist_images('train-images-idx3-ubyte.gz')\n",
    "y_train = read_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "X_test = read_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = read_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 784)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 784)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape:\", X_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"Test images shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to one hot encode labels\n",
    "def one_hot_encoder(labels):\n",
    "    encoded_labels = np.zeros(shape=(labels.shape[0], 10))\n",
    "    for idx, label in enumerate(labels):\n",
    "        encoded_labels[idx][label] = 1\n",
    "    return encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding labels\n",
    "y_train, y_test = one_hot_encoder(y_train), one_hot_encoder(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 784)\n",
      "Train labels shape: (60000, 10)\n",
      "Test images shape: (10000, 784)\n",
      "Test labels shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape:\", X_train.shape)\n",
    "print(\"Train labels shape:\", y_train.shape)\n",
    "print(\"Test images shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for normalizing pixels\n",
    "def normalize(array):\n",
    "    return array / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = normalize(X_train), normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed for random\n",
    "np.random.seed(42)\n",
    "\n",
    "# defining train valid split function\n",
    "def train_valid_split(valid_ratio = 0.1):\n",
    "    indices = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_X_train = X_train[indices]\n",
    "    shuffled_y_train = y_train[indices]\n",
    "\n",
    "    split_index = int(valid_ratio * shuffled_X_train.shape[0])\n",
    "\n",
    "    # return X_train, y_train, X_valid, y_valid\n",
    "    return shuffled_X_train[split_index:], shuffled_y_train[split_index:], shuffled_X_train[:split_index], shuffled_y_train[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) (54000, 10) (6000, 784) (6000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_valid, y_valid = train_valid_split()\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLu activation function\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "# ReLu prime function\n",
    "def relu_prime(x):\n",
    "    return x > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction for initializing model structure\n",
    "def struct_model():\n",
    "    W1 = np.random.uniform(low = -1., high= 1., size=(784, 784))\n",
    "    b1 = np.random.uniform(low = -1., high= 1., size=(1, 784))\n",
    "\n",
    "    W2 = np.random.uniform(low = -1., high= 1., size=(784, 10))\n",
    "    b2 = np.random.uniform(low = -1., high= 1., size=(1, 10))\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will declare weights and biases as global variables\n",
    "###############################\n",
    "W1, b1, W2, b2 = struct_model()\n",
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward function to calculate the output\n",
    "def feed_forward():\n",
    "    Z1 = np.dot(X_train, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    \n",
    "    # Softmax normalization\n",
    "    Z2 -= np.max(Z2, axis=1, keepdims=True)  # Subtracting the max for numerical stability, otherwise getting NaN and inf values\n",
    "    pred = np.exp(Z2) / np.sum(np.exp(Z2), axis=1, keepdims=True)\n",
    "\n",
    "    return Z1, A1, Z2, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use cross-entropy loss in back propogation and in metrics along with accuracy\n",
    "def cross_entropy_loss(y_pred):\n",
    "    \n",
    "    m = y_train.shape[0]\n",
    "    epsilon = 1e-10  # Small constant to avoid division by zero\n",
    "    loss = -np.sum(y_train * np.log(y_pred + epsilon)) / m\n",
    "    return loss\n",
    "\n",
    "def accuracy(pred):\n",
    "    \n",
    "    global y_train\n",
    "    return np.sum(np.argmax(pred,axis=1) == np.argmax(y_train, axis=1)) / y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for predicting the digit in the MNIST dataset image\n",
    "def predict(img):\n",
    "    Z1 = np.dot(img, W1) + b1\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    # Softmax normalization\n",
    "    Z2 -= np.max(Z2, axis=1, keepdims=True)  # Subtract the max for numerical stability\n",
    "    pred = np.exp(Z2) / np.sum(np.exp(Z2), axis=1, keepdims=True)\n",
    "\n",
    "    return np.argmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining another function to calculate accuracy for validation set\n",
    "def valid_accuracy():\n",
    "    global X_valid, y_valid\n",
    "\n",
    "    preds = []\n",
    "    for i in range(X_valid.shape[0]):\n",
    "        pred = predict(X_valid[i])\n",
    "        preds.append(pred)\n",
    "    pred = np.array(preds)\n",
    "\n",
    "    m = y_valid.shape[0]\n",
    "    \n",
    "    acc = np.sum(np.argmax(y_valid, axis=1) == pred) / m\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(Z1, A1, Z2, pred):\n",
    "    m = X_train.shape[0] # total # of entries\n",
    "\n",
    "    # calculate gradients of cross-entropy loss with respect to Z2\n",
    "    dZ2 = pred - y_train\n",
    "\n",
    "    # gradients of W2 and b2\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "    # gradients of A1 and Z1\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * relu_prime(Z1)\n",
    "\n",
    "    # gradients of W1 and b1\n",
    "    dW1 = np.dot(X_train.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    return dW1, db1, dW2, db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(dW1, db1, dW2, db2, learning_rate):\n",
    "    global W1\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    global b1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    global W2\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    global b2\n",
    "    b2 = b2 - learning_rate * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model checkpoint callback -> saving the weights and biases of the model with best validation accuracy\n",
    "def model_checkpoint(best_val_acc, current_val_acc):\n",
    "    path = \"weights/\"\n",
    "    if current_val_acc >= best_val_acc:\n",
    "        best_val_acc = current_val_acc\n",
    "        np.save(path + \"W1.npy\", W1)\n",
    "        np.save(path + \"b1.npy\", b1)\n",
    "        np.save(path + \"W2.npy\", W2)\n",
    "        np.save(path + \"b2.npy\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_gradient_descent(number_of_iterations, learning_rate):\n",
    "    # my weights and biases are global variables\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    best_val_acc = 0\n",
    "\n",
    "    for i in range(number_of_iterations):\n",
    "        \n",
    "        # feed forward step\n",
    "        Z1, A1, Z2, pred = feed_forward()\n",
    "\n",
    "        # back propagation step\n",
    "        dW1, db1, dW2, db2 = back_propagation(Z1, A1, Z2, pred)\n",
    "\n",
    "        # adding gradients to weights and biases\n",
    "        update_weights(dW1, db1, dW2, db2, learning_rate)\n",
    "\n",
    "        # calculating and printing metrics\n",
    "        train_loss = cross_entropy_loss(pred)\n",
    "        train_acc = accuracy(pred)\n",
    "        valid_acc = valid_accuracy()\n",
    "\n",
    "        model_checkpoint(best_val_acc, valid_acc)\n",
    "\n",
    "        print(\"Iteration {:<4}: Train Loss: {:.2f}, Train Accuracy: {:.2f}, Valid Accuracy: {:.2f}\".format(i+1, train_loss, train_acc, valid_acc))\n",
    "        print(\"-\"*80)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the model on the test set \n",
    "def evaluate():\n",
    "    global X_test, y_test\n",
    "    correct = 0\n",
    "    for i in range(X_test.shape[0]):\n",
    "        pred = predict(X_test[i])\n",
    "        correct += (pred == np.argmax(y_test[i]))\n",
    "    return correct/len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCHS = 100\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1   : Train Loss: 19.82, Train Accuracy: 0.11, Valid Accuracy: 0.17\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 2   : Train Loss: 18.06, Train Accuracy: 0.16, Valid Accuracy: 0.22\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 3   : Train Loss: 16.42, Train Accuracy: 0.22, Valid Accuracy: 0.26\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 4   : Train Loss: 16.21, Train Accuracy: 0.26, Valid Accuracy: 0.25\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 5   : Train Loss: 16.13, Train Accuracy: 0.26, Valid Accuracy: 0.39\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 6   : Train Loss: 12.99, Train Accuracy: 0.38, Valid Accuracy: 0.49\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 7   : Train Loss: 10.79, Train Accuracy: 0.50, Valid Accuracy: 0.49\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 8   : Train Loss: 10.36, Train Accuracy: 0.50, Valid Accuracy: 0.60\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 9   : Train Loss: 8.34, Train Accuracy: 0.59, Valid Accuracy: 0.63\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 10  : Train Loss: 7.37, Train Accuracy: 0.63, Valid Accuracy: 0.68\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 11  : Train Loss: 6.15, Train Accuracy: 0.68, Valid Accuracy: 0.71\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 12  : Train Loss: 5.20, Train Accuracy: 0.72, Valid Accuracy: 0.73\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 13  : Train Loss: 4.89, Train Accuracy: 0.73, Valid Accuracy: 0.74\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 14  : Train Loss: 4.62, Train Accuracy: 0.74, Valid Accuracy: 0.74\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 15  : Train Loss: 4.42, Train Accuracy: 0.75, Valid Accuracy: 0.76\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 16  : Train Loss: 4.15, Train Accuracy: 0.76, Valid Accuracy: 0.76\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 17  : Train Loss: 4.01, Train Accuracy: 0.77, Valid Accuracy: 0.77\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 18  : Train Loss: 3.81, Train Accuracy: 0.78, Valid Accuracy: 0.78\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 19  : Train Loss: 3.70, Train Accuracy: 0.78, Valid Accuracy: 0.78\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 20  : Train Loss: 3.57, Train Accuracy: 0.79, Valid Accuracy: 0.79\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 21  : Train Loss: 3.49, Train Accuracy: 0.79, Valid Accuracy: 0.79\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 22  : Train Loss: 3.41, Train Accuracy: 0.80, Valid Accuracy: 0.79\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 23  : Train Loss: 3.35, Train Accuracy: 0.80, Valid Accuracy: 0.80\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 24  : Train Loss: 3.29, Train Accuracy: 0.80, Valid Accuracy: 0.80\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 25  : Train Loss: 3.24, Train Accuracy: 0.81, Valid Accuracy: 0.80\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 26  : Train Loss: 3.20, Train Accuracy: 0.81, Valid Accuracy: 0.80\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 27  : Train Loss: 3.15, Train Accuracy: 0.81, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 28  : Train Loss: 3.11, Train Accuracy: 0.81, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 29  : Train Loss: 3.07, Train Accuracy: 0.81, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 30  : Train Loss: 3.04, Train Accuracy: 0.82, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 31  : Train Loss: 3.00, Train Accuracy: 0.82, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 32  : Train Loss: 2.97, Train Accuracy: 0.82, Valid Accuracy: 0.81\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 33  : Train Loss: 2.94, Train Accuracy: 0.82, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 34  : Train Loss: 2.91, Train Accuracy: 0.82, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 35  : Train Loss: 2.88, Train Accuracy: 0.82, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 36  : Train Loss: 2.85, Train Accuracy: 0.83, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 37  : Train Loss: 2.82, Train Accuracy: 0.83, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 38  : Train Loss: 2.80, Train Accuracy: 0.83, Valid Accuracy: 0.82\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 39  : Train Loss: 2.77, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 40  : Train Loss: 2.75, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 41  : Train Loss: 2.72, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 42  : Train Loss: 2.70, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 43  : Train Loss: 2.67, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 44  : Train Loss: 2.65, Train Accuracy: 0.83, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 45  : Train Loss: 2.63, Train Accuracy: 0.84, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 46  : Train Loss: 2.61, Train Accuracy: 0.84, Valid Accuracy: 0.83\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 47  : Train Loss: 2.59, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 48  : Train Loss: 2.57, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 49  : Train Loss: 2.55, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 50  : Train Loss: 2.53, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 51  : Train Loss: 2.51, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 52  : Train Loss: 2.50, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 53  : Train Loss: 2.48, Train Accuracy: 0.84, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 54  : Train Loss: 2.46, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 55  : Train Loss: 2.45, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 56  : Train Loss: 2.43, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 57  : Train Loss: 2.41, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 58  : Train Loss: 2.40, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 59  : Train Loss: 2.38, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 60  : Train Loss: 2.37, Train Accuracy: 0.85, Valid Accuracy: 0.84\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 61  : Train Loss: 2.35, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 62  : Train Loss: 2.34, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 63  : Train Loss: 2.32, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 64  : Train Loss: 2.31, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 65  : Train Loss: 2.30, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 66  : Train Loss: 2.28, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 67  : Train Loss: 2.27, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 68  : Train Loss: 2.26, Train Accuracy: 0.85, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 69  : Train Loss: 2.25, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 70  : Train Loss: 2.23, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 71  : Train Loss: 2.22, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 72  : Train Loss: 2.21, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 73  : Train Loss: 2.20, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 74  : Train Loss: 2.19, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 75  : Train Loss: 2.17, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 76  : Train Loss: 2.16, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 77  : Train Loss: 2.15, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 78  : Train Loss: 2.14, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 79  : Train Loss: 2.13, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 80  : Train Loss: 2.12, Train Accuracy: 0.86, Valid Accuracy: 0.85\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 81  : Train Loss: 2.11, Train Accuracy: 0.86, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 82  : Train Loss: 2.10, Train Accuracy: 0.86, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 83  : Train Loss: 2.09, Train Accuracy: 0.86, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 84  : Train Loss: 2.08, Train Accuracy: 0.86, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 85  : Train Loss: 2.07, Train Accuracy: 0.86, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 86  : Train Loss: 2.06, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 87  : Train Loss: 2.05, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 88  : Train Loss: 2.04, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 89  : Train Loss: 2.03, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 90  : Train Loss: 2.02, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 91  : Train Loss: 2.01, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 92  : Train Loss: 2.01, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 93  : Train Loss: 2.00, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 94  : Train Loss: 1.99, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 95  : Train Loss: 1.98, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 96  : Train Loss: 1.97, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 97  : Train Loss: 1.96, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 98  : Train Loss: 1.95, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 99  : Train Loss: 1.95, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n",
      "Iteration 100 : Train Loss: 1.94, Train Accuracy: 0.87, Valid Accuracy: 0.86\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# starting the gradient descent algorithm\n",
    "start_gradient_descent(NUMBER_OF_EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the best weights and biases\n",
    "\n",
    "path = \"weights/\"\n",
    "W1 = np.load(path + \"W1.npy\")\n",
    "b1 = np.load(path + \"b1.npy\")\n",
    "W2 = np.load(path + \"W2.npy\")\n",
    "b2 = np.load(path + \"b2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "# evaluting the accuracy of the model on the test set\n",
    "test_acc = evaluate()\n",
    "print('Test Accuracy: {:.2f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets:  [7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]\n",
      "Preds:    [7, 2, 1, 0, 9, 1, 4, 8, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4]\n",
      "\n",
      "Results:  ['T', 'T', 'T', 'T', 'F', 'T', 'T', 'F', 'F', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T']\n"
     ]
    }
   ],
   "source": [
    "# testing on the first 20 images in the test set\n",
    "def compare(idx):\n",
    "    preds = []\n",
    "    targets = []\n",
    "    results = []\n",
    "    for i in range(idx):\n",
    "        preds.append(predict(X_test[i]))\n",
    "        targets.append(np.argmax(y_test[i]))\n",
    "        results.append(\"T\" if preds[i] == targets[i] else \"F\")\n",
    "\n",
    "    print(\"Targets: \", targets)\n",
    "    print(\"Preds:   \", preds)\n",
    "    print(\"\\nResults: \", results)\n",
    "\n",
    "compare(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
